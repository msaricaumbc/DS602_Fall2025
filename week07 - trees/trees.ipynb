{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Learning with [Decision Trees](https://scikit-learn.org/stable/modules/tree.html)\n",
    "\n",
    "## Agenda\n",
    "- Decision trees and metrics.  \n",
    "- Decision tree for classification.  \n",
    "- Decision tree for regression.  \n",
    "- Random forests.  \n",
    "\n",
    "## Resources\n",
    "[dtreeviz - package for visualizing decision trees](https://github.com/parrt/dtreeviz)\n",
    "<br>[Leo Breiman's Random Forest Notes](https://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm)\n",
    "\n",
    "\n",
    "Contains material from:\n",
    "- Machine Learning with Python 3rd Edition, Pages 90-103.    \n",
    "- The Hundred-Page Machine Learning Book, Pages 27-30. \n",
    "- Hands-on Machine Learning with Scikit-Learn, Keras & TensorFlow, Pages 175-211.  \n",
    "\n",
    "We've likely seen and use some sort of decision trees all of the time.\n",
    "\n",
    "<img src='./diagrams/sample-dt.png' style='width: 600px;'>\n",
    "\n",
    "[Image source Python Machine Learning 3rd Edition, Page 91](https://github.com/rasbt/python-machine-learning-book-3rd-edition/tree/master/ch03)\n",
    "\n",
    "From [The Hundred-Page Machine Learning Book by Burkov](http://themlbook.com):\n",
    "\n",
    "> A decision trees can be represented by an acyclic graph that can be used to make decisions. In each branching node of the graph, a specific feature $j$ of the feature vector is examined. If the value of the feature is below a specific threshold, then the left branch is followed; otherwise, the right branch is followed. As the leaf node is reached, the decision is made about the class to which the example belongs.\n",
    "\n",
    "\n",
    "## Pros:\n",
    "- Very interpretable (white box model).  \n",
    "- Decisions can be traced and visualized.  \n",
    "- Can be used for classification or regression.  \n",
    "- Accepts continous and discrete features.  \n",
    "- Robust to outliers and other \"bad\" data.  \n",
    "- Doesn't require feature scaling or centering.  \n",
    "- No assumptions about the data (compared to the linearity assumption for linear regression).  \n",
    "\n",
    "## Cons:\n",
    "- Very easy to overfit, though a hyperparameter can address this.  \n",
    "- Requires a lot of hyperparameter tuning.  \n",
    "- Depending on the implementation, the solution may not be optimal.  \n",
    "- Very sensitive to differences between the training and test sets.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nonparametric model\n",
    "Logistic regression finds an optimal solution by building a parametric model to minimize the log likelihood, $f_{w^*, b*}$.\n",
    "\n",
    "Decision trees constructs a nonparametric model to approximately optimize, $f(x)\\equiv Pr(y=1|x)$.\n",
    "- It doesn't have to use each variable, so no weights like in logistic regression.  \n",
    "- No predetermined number of parameters to learn weights - they aren't defined prior to training.\n",
    "\n",
    "## Algorithms\n",
    "There are multiple algorithms that can be used to build decision trees.\n",
    "- [Classification and Regression Tree (CART)](https://en.wikipedia.org/wiki/Decision_tree_learning)  \n",
    "- [ID3](https://en.wikipedia.org/wiki/ID3_algorithm)  \n",
    "- [C4.5](https://en.wikipedia.org/wiki/C4.5_algorithm)    \n",
    "\n",
    "scikit-learn uses CART. It will produce nodes that always have two children (yes and no). ID3 and other algorithms can produce trees that contain more than two children. scikit-learn implementation doesn't support categorical variables, so you'll still need to turn them into numbers.\n",
    "\n",
    "From [scikit-learn:](https://scikit-learn.org/stable/modules/tree.html)  \n",
    "**ID3**  \n",
    "(Iterative Dichotomiser 3) was developed in 1986 by Ross Quinlan. The algorithm creates a multiway tree, finding for each node (i.e. in a greedy manner) the categorical feature that will yield the largest information gain for categorical targets. Trees are grown to their maximum size and then a pruning step is usually applied to improve the ability of the tree to generalise to unseen data.\n",
    "\n",
    "**C4.5**  \n",
    "C4.5 is the successor to ID3 and removed the restriction that features must be categorical by dynamically defining a discrete attribute (based on numerical variables) that partitions the continuous attribute value into a discrete set of intervals. C4.5 converts the trained trees (i.e. the output of the ID3 algorithm) into sets of if-then rules. These accuracy of each rule is then evaluated to determine the order in which they should be applied. Pruning is done by removing a ruleâ€™s precondition if the accuracy of the rule improves without it.\n",
    "\n",
    "**CART**  \n",
    "CART (Classification and Regression Trees) is very similar to C4.5, but it differs in that it supports numerical target variables (regression) and does not compute rule sets. CART constructs binary trees using the feature and threshold that yield the largest information gain at each node.\n",
    "\n",
    "\n",
    "## Metrics used in Decision Trees\n",
    "Information gain - this is maximized at each split:\n",
    "$$\n",
    "IG(D_{p,f})=I(D_p)-\\sum\\frac{N_j}{N_p}I(D_j)\n",
    "$$\n",
    "\n",
    "Using either\n",
    "\n",
    "(1) Gini impurity - measures the *impurity* of the classes. A gini score of 0 means that node only contains examples of a single class. You'll want this to be as close to 0 as possible (without overfitting) in the terminal leafs.\n",
    "$$\n",
    "G_{i} = 1 - \\sum(p_{i,k}^2)\n",
    "$$\n",
    "\n",
    "$p_{i,k}$ is the ratio of class $k$ instances among the training instances in the $i^{th}$ node.\n",
    "\n",
    "or (2) Entropy - another impurity measure, originated in themodynamics. Entropy is 0 when all classes are identical.  \n",
    "$$\n",
    "H_{i}=-\\sum{p_{i,k}log_{2}(p_{i,k})}\n",
    "$$\n",
    "\n",
    "Both can be used in the objective function.\n",
    "- Most of the time the trees will be similar.  \n",
    "- Gini is less complicated and will run slightly faster.  \n",
    "- Entropy tends to make slightly more balanced trees and gini tends to favor the larger class.  \n",
    "- Entropy will be at its maximum at 1 when the classes have an uniform distribution in the node.  \n",
    "\n",
    "For a 2-class problem, gini will have a maximum of 0.5, $1-\\sum(0.5^2)=0.5$\n",
    "\n",
    "<img src='./diagrams/simple-example.png' style='width: 500px;'>\n",
    "\n",
    "[Image source Python Machine Learning 3rd Edition, Page 93](https://github.com/rasbt/python-machine-learning-book-3rd-edition/tree/master/ch03)\n",
    "\n",
    "### Calculating gini:\n",
    "Starting:\n",
    "$$\n",
    "I_{G}(D_p) = 1 - (0.5^2 + 0.5^2) = 0.5\n",
    "$$\n",
    "\n",
    "#### Node A\n",
    "\n",
    "$$\n",
    "A:I_{G}(D_{left}) = 1 - (0.75^2 + 0.25^2) = 0.375\n",
    "$$\n",
    "\n",
    "<br>\n",
    "\n",
    "$$\n",
    "A:I_{G}(D_{right}) = 1 - (0.25^2 + 0.75^2) = 0.375\n",
    "$$\n",
    "\n",
    "<br>\n",
    "Information gain:\n",
    "\n",
    "$$\n",
    "A:IG_{G} = 0.5 - (0.5)(0.375)-(0.5)(0.375) = 0.125\n",
    "$$\n",
    "\n",
    "#### Node B\n",
    "\n",
    "$$\n",
    "B:I_{G}(D_{left}) = 1 - (0.33\\bar{3}^2 + 0.66\\bar{6}^2) = 0.\\bar{4}\n",
    "$$\n",
    "\n",
    "<br>\n",
    "\n",
    "$$\n",
    "B:I_{G}(D_{right}) = 1 - (1^2 + 0^2) = 0\n",
    "$$\n",
    "\n",
    "<br>\n",
    "Information gain:\n",
    "\n",
    "$$\n",
    "B:IG_{G} = 0.5-(0.75)(0.\\bar{4}) -  0= 0.\\bar{16}\n",
    "$$\n",
    "\n",
    "Gained more information in B, since the information gain was larger ($0.\\bar{16}\\gt0.125$).\n",
    "\n",
    "### Calculating entropy:\n",
    "\n",
    "$$\n",
    "I_H(D_p)=-(0.5log_2(0.5)+0.5log_2(0.5))=1\n",
    "$$\n",
    "\n",
    "#### Node A\n",
    "\n",
    "$$\n",
    "A:I_H(D_{left})=-(0.75log_2(0.75)+0.25log_2(0.25))=0.81\n",
    "$$\n",
    "\n",
    "<br>\n",
    "\n",
    "$$\n",
    "A:I_H(D_{right})=-(0.25log_2(0.25)+0.75log_2(0.75))=0.81\n",
    "$$\n",
    "\n",
    "<br>\n",
    "Information gain:\n",
    "\n",
    "$$\n",
    "A:IG_H=1-(0.5)(0.81)+(0.5)(0.81)=0.19\n",
    "$$\n",
    "\n",
    "#### Node B\n",
    "\n",
    "$$\n",
    "B:I_H(D_{left})=-(0.33log_2(0.33)+0.66log_2(0.66))=0.92\n",
    "$$\n",
    "\n",
    "<br>\n",
    "\n",
    "$$\n",
    "B:I_H(D_{right})=0\n",
    "$$\n",
    "\n",
    "<br>\n",
    "Information gain:\n",
    "\n",
    "$$\n",
    "B:IG_H=1-(\\frac{6}{8})(0.92)+0=0.31\n",
    "$$\n",
    "\n",
    "Gained more information in B, since the information gain was larger ($0.31\\gt0.19$).\n",
    "\n",
    "### Objective Function (CART)\n",
    "- Split training set into two subsets using a single feature $k$ and a threshold $t_k$ (e.g., height > 10).  \n",
    "- Searches for the feature and threshold that produces the smallest weighted impurity (Raschka uses the language \"maximizing information gain\").\n",
    "\n",
    "$$\n",
    "J{k,t_k}=\\frac{m_{left}}{m}G_{left} + \\frac{m_{right}}{m}G_{right}\n",
    "$$\n",
    "\n",
    "- $G_{left/right}$ measures the impurity of the left/right subset.  \n",
    "- $m_{left/right}$ is the number of instances in the left/right subset.    \n",
    "\n",
    "- Once the data is split, it splits each subset, then each subset of the subsets, ...   \n",
    "- It'll stop once it reaches either a maximum depth or if the splits don't reduce impurity.  \n",
    "\n",
    "### CART is a \"Greedy\"\n",
    "- Searches for optimum splits at the top and continues down for optimum splits.  \n",
    "- It doesn't look ahead or backwards to see if that split led to the lowest possible impurity.  \n",
    "- Therefore, not guaranteed to be optimal.  \n",
    "\n",
    "### Optimum Doesn't Exist\n",
    "This is an NP-Complete problem. The time required to guarantee the optimum solution approaches infinity even for smaller datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification\n",
    "Load the iris data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "irisX = iris['data']\n",
    "irisy = iris['target']\n",
    "irisNames = iris['feature_names']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the dataset into training and test datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(irisX, irisy, random_state=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit a tree with defaults and visualize the rules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "tree_model = DecisionTreeClassifier(criterion='gini', random_state=1)\n",
    "tree_model.fit(X_train, y_train)\n",
    "\n",
    "from sklearn import tree\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "tree.plot_tree(tree_model, feature_names=irisNames, fontsize=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Visualizing isn't crucial for modeling. It presents a nice interpretation, but we will use the metrics we discussed the past few weeks to evaluate the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Training accuracy: {tree_model.score(X_train, y_train):.2f}')\n",
    "print(f'Test accuracy: {tree_model.score(X_test, y_test):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can output probabilities, though not in the same way:\n",
    "> The predicted class probability is the fraction of samples of the same class in a leaf. Since the leafs was 100% pure, these \"probabilities\" will be zero or one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_model.predict_proba(X_test)[:5, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the `iris` case, since the tree fully split, the probabilities will be 0 or 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Seems to be overfitting. Trees can overfit on the training data if we don't control how deep they can grow and characteristics around samples per leaf.\n",
    "\n",
    "It isn't hard to see how. The below plot from scikit-learn provides an illustration of the decision boundaries.\n",
    "<img src='./diagrams/iris-decision-bounds.png' style='width: 500px;'>\n",
    "\n",
    "[Image source: scikit-learn](https://scikit-learn.org/stable/auto_examples/tree/plot_iris_dtc.html#sphx-glr-auto-examples-tree-plot-iris-dtc-py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularization\n",
    "- Instead of $L1$ and $L2$, there are different ways to prevent overfitting.  \n",
    "- Instead of incorporating penalties into the cost function, overfitting is controlled with a variety of hyperparameters:\n",
    "    - How deep the tree can growth (`max_depth`)  \n",
    "    - Samples needed for a split to be possible (`min_samples_split`)  \n",
    "    - Number of samples a leaf must have (`min_samples_leaf`)  \n",
    "    - Change in the impurity from node to node (`min_impurity_decrease`)  \n",
    "    - ...\n",
    "- You'll need to follow best practices for determining the values of these hyperparameters.  \n",
    "- For this small `iris` data, we'll want to do cross validation and a grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "tr_pipe = modeling_pipeline = Pipeline([\n",
    "        ('dt', DecisionTreeClassifier())\n",
    "        ]\n",
    "    )\n",
    "\n",
    "param_grid = [\n",
    "  {'dt__max_depth': [3,4,5,6,7,8],\n",
    "   'dt__min_samples_split': [2,4,6,8]\n",
    "  }\n",
    " ]\n",
    "\n",
    "iris_gs = GridSearchCV(estimator=tr_pipe, param_grid=param_grid, scoring='accuracy', refit=True)\n",
    "iris_gs = iris_gs.fit(X_train, y_train)\n",
    "\n",
    "iris_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_gs.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Using `refit=True` we retain the best estimates and can score the test data with the best estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_gs.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's about a 2-point improvement in our test accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \"Regularization\" resulted in a smaller tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "tree_model = DecisionTreeClassifier(criterion='gini', random_state=1, max_depth=3, min_samples_split=2)\n",
    "tree_model.fit(X_train, y_train)\n",
    "\n",
    "from sklearn import tree\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "tree.plot_tree(tree_model, feature_names=irisNames, fontsize=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(tree_model.predict_proba(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probabilities will match the leaf distributions:\n",
    "\n",
    "> .97058824 = 33/(0+33+1)\n",
    "\n",
    "> 0.4 = 2/(0+2+3)\n",
    "\n",
    "> 1.0 = 33/(0+0+33)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing Tree to Logistic Regression on the Credit Default Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "credit = pd.read_csv('https://raw.githubusercontent.com/msaricaumbc/DS_data/master/ds602/log_reg/Default.csv', index_col=0)\n",
    "\n",
    "# we created this last week\n",
    "credit['balance2income'] = credit['balance']/credit['income']\n",
    "credit['balance_student_int'] = np.where(credit['student']=='Yes', credit['balance'], 0)\n",
    "credit['income_student_int'] = np.where(credit['student']=='Yes', credit['income'], 0)\n",
    "credit['zero_balance'] = np.where(credit['balance'] == 0, 'Yes', 'No')\n",
    "\n",
    "credit_y = np.where(credit['default'] == 'Yes', 1, 0)\n",
    "\n",
    "credit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "creditFeatures = [x for x in credit.columns if x != 'default']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(credit[creditFeatures], credit_y, test_size=0.20)\n",
    "\n",
    "print(f'Training examples: {X_train.shape[0]:,}')\n",
    "print(f'Test examples: {X_test.shape[0]:,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The Logistic Regression Pipeline from Last Time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "nums = ['balance2income', 'balance', 'income', \n",
    "        'balance_student_int', 'income_student_int']\n",
    "\n",
    "ohes = ['student', 'zero_balance']\n",
    "\n",
    "processing_pipeline = ColumnTransformer(transformers=[\n",
    "    ('numscaling', StandardScaler(), nums),\n",
    "    ('dummys', OneHotEncoder(drop='first'), ohes)]\n",
    ")\n",
    "\n",
    "modeling_pipeline = Pipeline([\n",
    "    ('data_processing', processing_pipeline),\n",
    "    ('logreg', LogisticRegression())]\n",
    ")\n",
    "\n",
    "param_grid = [\n",
    "  {'logreg__class_weight': [None, 'balanced'], 'logreg__C':[0.01, 0.1, 1, 10, 100]}\n",
    " ]\n",
    "\n",
    "gcv_results = GridSearchCV(estimator=modeling_pipeline, \n",
    "                           param_grid=param_grid, scoring='recall', refit=True)\n",
    "gcv_results = gcv_results.fit(X_train, y_train)\n",
    "\n",
    "gcv_results.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_testp = gcv_results.predict(X_test)\n",
    "y_testpr_lr = gcv_results.predict_proba(X_test)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_testp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## versus a Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "nums = ['balance2income', 'balance', 'income', 'balance_student_int',\n",
    "        'income_student_int']\n",
    "ohes = ['student', 'zero_balance']\n",
    "\n",
    "processing_pipeline = ColumnTransformer(transformers=[\n",
    "    ('numscaling', StandardScaler(), nums),\n",
    "    ('dummys', OneHotEncoder(drop='first'), ohes)]\n",
    ")\n",
    "\n",
    "modeling_pipeline = Pipeline([\n",
    "    ('data_processing', processing_pipeline),\n",
    "    ('dt', DecisionTreeClassifier())]\n",
    ")\n",
    "\n",
    "param_grid = [\n",
    "  {'dt__max_depth': [2, 5, 10, 15, 20],\n",
    "   'dt__min_samples_split':[3, 5, 10, 20, 40],\n",
    "   'dt__min_samples_leaf': [2, 5],\n",
    "   'dt__class_weight':[None, 'balanced']\n",
    "  }\n",
    " ]\n",
    "\n",
    "gcv_results = GridSearchCV(estimator=modeling_pipeline, \n",
    "                           param_grid=param_grid, scoring='recall', refit=True)\n",
    "gcv_results = gcv_results.fit(X_train, y_train)\n",
    "\n",
    "gcv_results.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_testp = gcv_results.predict(X_test)\n",
    "y_testp_dt = gcv_results.predict_proba(X_test)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_testp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Slightly better recall with the Decision Tree, with about the same precision level.\n",
    "\n",
    "> All else equal, we'd probably prefer this to the logistic regression model if maximizing recall was our objective.\n",
    "\n",
    "#### We could compare the precision-recall curves to see if the threshold effects the classification:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ROC curves are appropriate when the observations are balanced between each class, whereas precision-recall curves are appropriate for imbalanced datasets.\n",
    "\n",
    "https://machinelearningmastery.com/roc-curves-and-precision-recall-curves-for-classification-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "def generate_pr(y, probs):\n",
    "    pr, rec, _ = precision_recall_curve(y, probs)\n",
    "    return pr, rec\n",
    "    \n",
    "pr_dt, rec_dt = generate_pr(y_test, y_testp_dt[:,1])\n",
    "pr_lr, rec_lr = generate_pr(y_test, y_testpr_lr[:,1])\n",
    "\n",
    "plt.plot(rec_dt, pr_dt,'-or')\n",
    "plt.plot(rec_lr, pr_lr,'-ob')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.legend(['Decision Tree','Logistic Regression'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rec_dt, pr_dt\n",
    "# rec_lr, pr_lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Less choices of probability thresholds with trees since the only probabilities outputted are those derived from the terminal leafs!\n",
    "\n",
    "> Also seeing a little bit of instability with the Logistic regression model. This isn't entirely uncommon.\n",
    "\n",
    "> If we visualized this tree, we'd probably find all the defaulted examples mostly in a single leaf."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What about looking at accuracy, maybe Decision Trees handle the class imbalance?\n",
    "\n",
    "#### Remember: Accuracy with Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "nums = ['balance2income', 'balance', 'income', \n",
    "        'balance_student_int', 'income_student_int']\n",
    "\n",
    "ohes = ['student', 'zero_balance']\n",
    "\n",
    "processing_pipeline = ColumnTransformer(transformers=[\n",
    "    ('numscaling', StandardScaler(), nums),\n",
    "    ('dummys', OneHotEncoder(drop='first'), ohes)]\n",
    ")\n",
    "\n",
    "modeling_pipeline = Pipeline([\n",
    "    ('data_processing', processing_pipeline),\n",
    "    ('logreg', LogisticRegression())]\n",
    ")\n",
    "\n",
    "param_grid = [\n",
    "  {'logreg__class_weight': [None], 'logreg__C':[0.01, 0.1, 1, 10, 100]}\n",
    " ]\n",
    "\n",
    "gcv_results = GridSearchCV(estimator=modeling_pipeline, \n",
    "                           param_grid=param_grid, scoring='accuracy', refit=True)\n",
    "gcv_results = gcv_results.fit(X_train, y_train)\n",
    "\n",
    "y_testp = gcv_results.predict(X_test)\n",
    "y_testpr_lr = gcv_results.predict_proba(X_test)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_testp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compared with the Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "nums = ['balance2income', 'balance', 'income', 'balance_student_int',\n",
    "        'income_student_int']\n",
    "ohes = ['student', 'zero_balance']\n",
    "\n",
    "processing_pipeline = ColumnTransformer(transformers=[\n",
    "    ('numscaling', StandardScaler(), nums),\n",
    "    ('dummys', OneHotEncoder(drop='first'), ohes)]\n",
    ")\n",
    "\n",
    "modeling_pipeline = Pipeline([\n",
    "    ('data_processing', processing_pipeline),\n",
    "    ('dt', DecisionTreeClassifier())]\n",
    ")\n",
    "\n",
    "param_grid = [\n",
    "  {'dt__max_depth': [2, 5, 10, 15, 20],\n",
    "   'dt__min_samples_split':[3, 5, 10, 20, 40],\n",
    "   'dt__min_samples_leaf': [2, 5],\n",
    "   'dt__class_weight':[None]\n",
    "  }\n",
    " ]\n",
    "\n",
    "gcv_results = GridSearchCV(estimator=modeling_pipeline, \n",
    "                           param_grid=param_grid, scoring='accuracy', refit=True)\n",
    "gcv_results = gcv_results.fit(X_train, y_train)\n",
    "\n",
    "y_testp = gcv_results.predict(X_test)\n",
    "y_testpr_lr = gcv_results.predict_proba(X_test)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_testp))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Looks like this handles imbalances similar to Logistic Regression, which means the larger class will crowd-out the smaller class. This is because Decision Trees are looking to minimize the impurity and impurity will be very low with imbalanced classses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression with Trees\n",
    "For regression, CART uses the same concept, but gini or entropy is replaced with mean squared error:\n",
    "\n",
    "$$\n",
    "H(Q_m) = \\frac{1}{N_m}\\sum(y-\\bar{y_m})^2\n",
    "$$\n",
    "\n",
    "or Half-Poisson deviance when you have count or frequency:\n",
    "\n",
    "$$\n",
    "H(Q_m) = \\frac{1}{N_m}\\sum(ylog\\frac{y}{\\bar{y_m}}-y+\\bar{y_m})\n",
    "$$\n",
    "\n",
    "> Like classification trees, the prediction for a regression is really a leaf-value so it will have different prediction distributions that linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a random dataset\n",
    "rng = np.random.RandomState(1)\n",
    "X = np.sort(5 * rng.rand(80, 1), axis=0)\n",
    "y = np.sin(X).ravel()\n",
    "y[::5] += 3 * (0.5 - rng.rand(16))\n",
    "\n",
    "plt.plot(X,y, 'ro')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine the difference between a linear regression and decision tree regressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "X_testvals = np.arange(0,5,0.01).reshape(-1,1)\n",
    "\n",
    "ols_yhat = LinearRegression().fit(X,y).predict(X_testvals)\n",
    "dtr_yhat = DecisionTreeRegressor().fit(X,y).predict(X_testvals)\n",
    "\n",
    "plt.plot(X,y, 'ro')\n",
    "plt.plot(X_testvals, ols_yhat, 'b-')\n",
    "plt.plot(X_testvals, dtr_yhat, 'g--')\n",
    "plt.legend(['Training Data', 'OLS on Test', 'Tree on Test'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Again, very sensitive to outliers and you can see the discontinuities that get created. It'll appear like a step function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_3 = DecisionTreeRegressor(max_depth=3)\n",
    "dtr_yhat = tree_3.fit(X,y).predict(X_testvals)\n",
    "\n",
    "plt.plot(X,y, 'ro')\n",
    "plt.plot(X_testvals, ols_yhat, 'b-')\n",
    "plt.plot(X_testvals, dtr_yhat, 'g--')\n",
    "plt.legend(['Training Data', 'OLS on Test', 'Tree on Test'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "tree.plot_tree(tree_3, fontsize=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's compare a more reasonable example with the California Housing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "housing = pd.read_csv('https://raw.githubusercontent.com/msaricaumbc/DS_data/master/ds602/regression/housing.csv')\n",
    "housing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Need an imputer for total bedrooms\n",
    "\n",
    "> 1 categorical variable that'll need to be expanded to dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "cat_vars = ['ocean_proximity']\n",
    "\n",
    "num_vars = ['housing_median_age', 'total_rooms', 'total_bedrooms',\n",
    "            'population', 'households', 'median_income']\n",
    "\n",
    "num_pipeline = Pipeline([('impute_missing', SimpleImputer(strategy='median')),\n",
    "                           ('standardize_num', StandardScaler())\n",
    "                        ])\n",
    "\n",
    "cat_pipeline = Pipeline([('impute_missing_cats', SimpleImputer(strategy='most_frequent')),\n",
    "                          ('create_dummies_cats', OneHotEncoder(handle_unknown='ignore', drop='first'))])\n",
    "\n",
    "housing_fpipeline = ColumnTransformer(transformers=[('proc_numeric', num_pipeline, num_vars),\n",
    "                                                      ('create_dummies', cat_pipeline, cat_vars)])\n",
    "\n",
    "print('Housing data pipeline created.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into training/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "housing_y = housing['median_house_value']\n",
    "housing_features = [x for x in housing.columns if x != 'median_house_value']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(housing[housing_features], housing_y, test_size=0.20)\n",
    "\n",
    "print(f'Training sample: {X_train.shape[0]:,}')\n",
    "print(f'Test sample: {X_test.shape[0]:,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge with varying Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "ridge_pipeline = Pipeline([\n",
    "    ('data_processing', housing_fpipeline),\n",
    "    ('ridge', Ridge())]\n",
    ")\n",
    "\n",
    "param_grid = [{'ridge__alpha': [0.001, 0.01, 0.1, 1, 10, 100]}]\n",
    "\n",
    "ridge_results = GridSearchCV(estimator=ridge_pipeline, param_grid=param_grid, scoring='r2', refit=True)\n",
    "ridge_results = ridge_results.fit(X_train, y_train)\n",
    "ridge_yhat = ridge_results.predict(X_test)\n",
    "\n",
    "ridge_results.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "dtr_pipeline = Pipeline([\n",
    "    ('data_processing', housing_fpipeline),\n",
    "    ('dtr', DecisionTreeRegressor())]\n",
    ")\n",
    "\n",
    "param_grid = [{'dtr__max_depth': [2, 4, 6, 8, 10, 12],\n",
    "               'dtr__min_samples_leaf': [5, 10, 20, 50, 100],\n",
    "               'dtr__min_samples_split': [5, 10, 15, 25]\n",
    "              }]\n",
    "\n",
    "dtr_results = GridSearchCV(estimator=dtr_pipeline, param_grid=param_grid, scoring='r2', refit=True)\n",
    "dtr_results = dtr_results.fit(X_train, y_train)\n",
    "dtr_yhat = dtr_results.predict(X_test)\n",
    "\n",
    "dtr_results.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(y_test, ridge_yhat, 'ro', alpha=0.1)\n",
    "plt.plot(y_test, dtr_yhat, 'bo', alpha=0.1)\n",
    "plt.legend(['Ridge','Decision Tree'])\n",
    "plt.xlabel('Actual')\n",
    "plt.ylabel('Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Not as sensitive to truncated distributions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Max Ridge Prediction: {ridge_yhat.max():,}')\n",
    "print(f'Max Regression Tree Prediction: {dtr_yhat.max():,}')\n",
    "print(f'Max House Value in Test Data: {y_test.max():,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result has a better overall fit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2r = ridge_results.score(X_test, y_test)\n",
    "\n",
    "print(f'Ridge R-squared: {r2r:.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2dt = dtr_results.score(X_test, y_test)\n",
    "\n",
    "print(f'Regression Tree R-squared: {r2dt:.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_resid = y_test - ridge_yhat\n",
    "dtr_resid = y_test - dtr_yhat\n",
    "\n",
    "plt.plot(y_test, ridge_resid, 'ro', alpha=0.1)\n",
    "plt.plot(y_test, dtr_resid, 'bo', alpha=0.1)\n",
    "plt.legend(['Ridge','Decision Tree'])\n",
    "plt.xlabel('Actual')\n",
    "plt.ylabel('Residual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(ridge_resid, bins=100)\n",
    "plt.title('Residuals from Ridge')\n",
    "plt.xlim((-800000, 800000))\n",
    "plt.show()\n",
    "\n",
    "plt.hist(dtr_resid, bins=100)\n",
    "plt.title('Residuals from Decision Tree')\n",
    "plt.xlim((-800000, 800000))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Better behavior in residuals with the truncated values at 500,000  \n",
    "- Tighter distribution around zero.  \n",
    "- Would prefer the decision tree to ridge in this case.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forests\n",
    "An ensemble model that combines many weak learners that in compositie, create a strong learner.\n",
    "\n",
    "> Sometimes using just one model, even tuned, isn't going to give the best results.\n",
    "\n",
    "> Think of this, individual economic forecasters will each forecast GDP and those forecasts will have some type of range, say between 1.0 and 3.5 percent. Their average forecast 2.25% has historically been the best forecast.\n",
    "\n",
    "### Basic idea\n",
    "Given our training data:\n",
    "- Create many samples of the data w/ replacement (similar to bootstrapping). \n",
    "- Then we'll build a decision tree using a subset of the features - selected randomly.\n",
    "    - If we used the same set of features each time we'd get a bunch of correlated trees.  \n",
    "    - Good trees will tend to agree with each other.  \n",
    "    - Bad models will disagree on different ones.  \n",
    "- We take the majority vote for our prediction.\n",
    "\n",
    "$$\n",
    "y \\leftarrow \\hat{y}(x)=\\frac{1}{B}\\sum{f_b(x)}\n",
    "$$\n",
    "\n",
    "Where $B$ is the number of trees.\n",
    "\n",
    "> A nice benefit, since it performs bootstrapping, it mitigrates noise that will be specific to the training dataset, so it won't carry as much of that noise when we evaluate our model on the tree set.\n",
    "\n",
    "<img src='./diagrams/bootstrap1.png' style='width: 600px'>\n",
    "\n",
    "Another nice byproduct are feature importances. These don't work with a pipeline, but you could extract these from standalone models and determine which features have the largest importance in relation to reducing impurity.\n",
    "> The higher, the more important the feature. The importance of a feature is computed as the (normalized) total reduction of the criterion brought by that feature. It is also known as the Gini importance.\n",
    "[scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier.feature_importances_)\n",
    "\n",
    "### Important Tuning Knobs\n",
    "- Number of trees we generate.  \n",
    "- Number of samples in each sample - keeping this small can increase the training data diversity and reduce overfitting.  \n",
    "\n",
    "#### Less important knobs\n",
    "- Samples per leaf.  \n",
    "- Samples per split. \n",
    "- How deep the trees can be.  \n",
    "\n",
    "### Minor Downsides\n",
    "- Not an interpretable model.  \n",
    "- Can't visualize like a single tree.  \n",
    "- Can be computationally expensive, especially with cross-validation and grid-search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "creditFeatures = [x for x in credit.columns if x != 'default']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(credit[creditFeatures], credit_y, test_size=0.20)\n",
    "\n",
    "print(f'Training examples: {X_train.shape[0]:,}')\n",
    "print(f'Test examples: {X_test.shape[0]:,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "nums = ['balance2income', 'balance', 'income', 'balance_student_int', 'income_student_int']\n",
    "ohes = ['student', 'zero_balance']\n",
    "\n",
    "processing_pipeline = ColumnTransformer(transformers=[\n",
    "    ('numscaling', StandardScaler(), nums),\n",
    "    ('dummys', OneHotEncoder(drop='first'), ohes)]\n",
    ")\n",
    "\n",
    "rf_pipeline = Pipeline([\n",
    "    ('data_processing', processing_pipeline),\n",
    "    ('rf', RandomForestClassifier())]\n",
    ")\n",
    "\n",
    "param_grid = [{'rf__max_depth': [5, 8, 10, 12],\n",
    "               'rf__n_estimators': [10, 50, 100],\n",
    "               'rf__class_weight': [None, 'balanced', 'balanced_subsample'],\n",
    "               'rf__max_samples': [1000, 2000, 5000]\n",
    "              }]\n",
    "\n",
    "rf_results = GridSearchCV(estimator=rf_pipeline, param_grid=param_grid, scoring='recall', refit=True)\n",
    "rf_results = rf_results.fit(X_train, y_train)\n",
    "rf_yhat = rf_results.predict(X_test)\n",
    "\n",
    "rf_results.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_testp = rf_results.predict(X_test)\n",
    "y_testp_rf = rf_results.predict_proba(X_test)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_testp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Didn't use all the potential knobs, but performed about the same as the decision tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Importance with Random Forests\n",
    "- The relative importance of features.  \n",
    "- How often the nodes use that feature reduce the impurity across the forest.  \n",
    "- The result is scaled so the importances sum to 1.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rnd_clf = RandomForestClassifier(n_estimators=500)\n",
    "rnd_clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "imps = list(zip(iris.feature_names, rnd_clf.feature_importances_))\n",
    "\n",
    "fi = pd.Series([x[1] for x in imps], index=[x[0] for x in imps])\n",
    "fi = fi.sort_values(ascending=True)\n",
    "\n",
    "fi.plot.barh()\n",
    "plt.title('Feature Importances', loc='left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://shap.readthedocs.io/en/latest/generated/shap.TreeExplainer.html "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another Example with Feature Importance using the breast cancer data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "X_cancer = cancer['data']\n",
    "y_cancer = cancer['target']\n",
    "\n",
    "X_cancer[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "cX_train, cX_test, cy_train, cy_test = train_test_split(X_cancer, y_cancer,\n",
    "                                                        test_size=0.2)\n",
    "\n",
    "print(f'Training examples: {cX_train.shape[0]:,}')\n",
    "print(f'Test examples: {cX_test.shape[0]:,}')\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {'n_estimators': [100, 200, 500, 750],\n",
    "          'max_depth': [1, 2, 5, 10]\n",
    "          \n",
    "         }\n",
    "\n",
    "rfm = GridSearchCV(RandomForestClassifier(), param_grid = params, cv=10,\n",
    "                  scoring='accuracy')\n",
    "\n",
    "rfm = rfm.fit(cX_train, cy_train)\n",
    "rfm.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Validation Best Score: {rfm.best_score_:.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Test Score: {rfm.score(cX_test, cy_test):.2%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- High explanatory power. \n",
    "- Good generalization.  \n",
    "- Safe to look at the feature importances.  \n",
    "\n",
    "> These have the same caveats as regression weights. If your model is very weak, looking at the feature importances can be very misleading and can look like p-value hacking.\n",
    "\n",
    "GridSearchCV doesn't support `feature_importances_`, so train a separate model with the chosen hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(max_depth=10).fit(cX_train, cy_train)\n",
    "impt = rf.feature_importances_\n",
    "\n",
    "impt = list(zip(cancer['feature_names'], impt))\n",
    "impt = pd.DataFrame(impt)\n",
    "impt.columns = ['feature', 'importance']\n",
    "impt = impt.set_index('feature')\n",
    "impt = impt.sort_values(by='importance', ascending=False)\n",
    "impt['cumulative'] = impt['importance'].cumsum()\n",
    "\n",
    "impt.plot.bar(figsize=(10,4))\n",
    "plt.title('Feature Importances from Random Forest', loc='left')\n",
    "plt.xlabel('')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wine Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "wine = pd.read_csv('https://raw.githubusercontent.com/msaricaumbc/DS_data/master/ds602/winequality-white.csv', sep=';')\n",
    "\n",
    "wine.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the data for NAs and types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable of Interest - Wine Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine.quality.value_counts().sort_index().plot.barh()\n",
    "plt.title('Wine Quality Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine = wine.query('quality > 3 and quality < 9')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Might be good candidate for a tree instead of linear regression\n",
    "- Could also try to model this as a classification problem  \n",
    "- One benefit with using regression vs. classification is we'll try to get close to the quality, with classification a 1 vs. 5 compared to a 4 vs. 5 is the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "wine_features = [x for x in wine.columns if x != 'quality']\n",
    "\n",
    "wX_train, wX_test, wy_train, wy_test = train_test_split(wine[wine_features],\n",
    "                                                        wine['quality'],\n",
    "                                                        test_size=0.20)\n",
    "\n",
    "print(f'Training examples: {wX_train.shape[0]:,}')\n",
    "print(f'Test examples: {wX_test.shape[0]:,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "wine_pipe = Pipeline([('scale', StandardScaler()), ('lm', LinearRegression())])\n",
    "wine_pipe = wine_pipe.fit(wX_train, wy_train)\n",
    "\n",
    "wine_training_score = wine_pipe.score(wX_train, wy_train)\n",
    "wine_test_score = wine_pipe.score(wX_test, wy_test)\n",
    "wine_pred = wine_pipe.predict(wX_test)\n",
    "\n",
    "print(f'Training score: {wine_training_score:.2%}')\n",
    "print(f'Test score: {wine_test_score:.2%}')\n",
    "\n",
    "plt.plot(wy_test, wine_pred, 'ro', alpha=0.1)\n",
    "plt.xlabel('Actual Quality')\n",
    "plt.ylabel('Predicted Quality')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {'n_estimators': [100],\n",
    "          'max_depth': [5, 10],\n",
    "          'criterion': ['squared_error', 'poisson']\n",
    "         }\n",
    "\n",
    "rfr = GridSearchCV(RandomForestRegressor(), param_grid = params, cv=10,\n",
    "                  scoring='r2', refit=True)\n",
    "\n",
    "rfr = rfr.fit(wX_train, wy_train)\n",
    "rfr.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Validation score: {rfr.score(wX_train, wy_train):.2%}')\n",
    "print(f'Test score: {rfr.score(wX_test, wy_test):.2%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Looks like we have overfitting; see the 25-point difference in the validation vs. test scores\n",
    "\n",
    "> Since the performance is so much better than linear regression, we'd probably go with this model, based on the 20-point difference in $R^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_pred2 = rfr.predict(wX_test)\n",
    "\n",
    "plt.plot(wy_test, wine_pred2, 'ro', alpha=0.1)\n",
    "plt.xlabel('Actual Quality')\n",
    "plt.ylabel('Predicted Quality')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(wine_pred2, wine_pred, 'ro', alpha=0.1)\n",
    "plt.xlabel('Random Forest')\n",
    "plt.ylabel('Linear Regression')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creative Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "wine_eval = pd.DataFrame(np.stack([wy_test, wine_pred, wine_pred2], axis=1))\n",
    "wine_eval.columns = ['test_value', 'lm_pred', 'rf_pred']\n",
    "wine_eval.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Could look at confusion matrices. \n",
    "- Look at rounding. \n",
    "- Maybe be could combined the predictions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round_eval = wine_eval.round(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(round_eval['test_value'].astype(int), \n",
    "                            round_eval['lm_pred'].astype(int), zero_division=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(round_eval['test_value'].astype(int), \n",
    "                            round_eval['rf_pred'].astype(int), zero_division=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Straight Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import warnings\n",
    "\n",
    "params = {'n_estimators': [100, 200]\n",
    "         }\n",
    "\n",
    "rfc = GridSearchCV(RandomForestClassifier(), param_grid = params, cv=10,\n",
    "                  scoring='accuracy', refit=True)\n",
    "\n",
    "rfc = rfc.fit(wX_train, wy_train)\n",
    "rfc.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_pred3 = rfc.predict(wX_test)\n",
    "\n",
    "print(classification_report(wy_test, wine_pred3, zero_division=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Looks like classification is better in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Readings\n",
    "- [scikit Decision Trees](https://scikit-learn.org/stable/modules/tree.html)  \n",
    "- [Decision tree - Wikipedia](https://en.wikipedia.org/wiki/Decision_tree_learning)  \n",
    "- [Chapter 9.2 Elements of Statistical Learning](https://web.stanford.edu/~hastie/ElemStatLearn/)  \n",
    "- [Python Machine Learning 3rd Edition, Pages 90-102](https://github.com/rasbt/python-machine-learning-book-3rd-edition/tree/master/ch03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
